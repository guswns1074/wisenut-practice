{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from urllib import parse\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "def url_to_image(url):\n",
    "    try:\n",
    "        res = urllib.request.urlopen(url)\n",
    "        image = np.asarray(bytearray(res.read()), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    except:\n",
    "        image = cv2.imread('sample.jpg')\n",
    "    return image\n",
    "\n",
    "def ocr(image):\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img_gray = cv2.bitwise_not(cv2.adaptiveThreshold(img_gray, 255, cv2.THRESH_BINARY, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 75, 10))\n",
    "    text = pytesseract.image_to_string(img_gray, lang=\"kor\")\n",
    "    return text\n",
    "\n",
    "def get_blog_url(query,start_date,stop_date):\n",
    "    browser=\"C:\\\\Users\\CPB06GameN\\Anaconda3\\envs\\chromedriver.exe\"\n",
    "    driver=webdriver.Chrome(browser)\n",
    "\n",
    "#     query = '다이슨'\n",
    "#     start_date = '20190902'\n",
    "#     stop_date = '20190908'\n",
    "    url = 'https://search.naver.com/search.naver?where=post&query='+query+'&date_from='+start_date+'&date_to='+stop_date+'&date_option=8&post_blogurl=naver.com'\n",
    "    driver.get(url)\n",
    "\n",
    "    total = driver.find_element_by_css_selector('#main_pack > div.blog.section._blogBase._prs_blg > div > span').text\n",
    "    total = total.split(' ')\n",
    "    for i in range(0,len(total)):\n",
    "        if len(re.findall('.*건',total[i])) > 0:\n",
    "            tot = total[i]\n",
    "    tot = tot.replace(',','').replace('건','')\n",
    "    page = int(tot)//10\n",
    "    if page > 100:\n",
    "        page = 100\n",
    "    url_list = []\n",
    "\n",
    "    for i in range(0,page):\n",
    "        for j in range(1,11):\n",
    "            blog_url = driver.find_element_by_css_selector('#sp_blog_'+str(j)+' > dl > dt > a').get_attribute('href')\n",
    "            url_list.append(blog_url)\n",
    "        try:\n",
    "            driver.find_element_by_css_selector('#main_pack > div.paging > a.next').click() \n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            pass\n",
    "    return url_list\n",
    "\n",
    "def blog_info(url):\n",
    "    browser=\"C:\\\\Users\\CPB06GameN\\Anaconda3\\envs\\chromedriver.exe\"\n",
    "    driver=webdriver.Chrome(browser)\n",
    "    driver.get(url)\n",
    "    driver.switch_to.frame('mainFrame')\n",
    "    html = driver.page_source\n",
    "    \n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    text_list = soup.find_all('div',{'class' : 'se-module se-module-text'})\n",
    "    fin = ''\n",
    "    last_text = ''\n",
    "    img_url = ''\n",
    "    title = ''\n",
    "    date = ''\n",
    "    for i in text_list:\n",
    "        try:\n",
    "            txt = i.find_all('p',{'class':'se-text-paragraph se-text-paragraph-align-center'})\n",
    "        except:\n",
    "            pass\n",
    "        for j in txt:\n",
    "            fin = fin + j.text\n",
    "            last_text = j.text\n",
    "    fin = fin.replace('\\u200b','')\n",
    "    try:\n",
    "        date = soup.find('span',{'class': 'se_publishDate pcol2'}).text\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        title = soup.find('div',{'class': 'se-module se-module-text se-title-text'}).text.replace('\\n','')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        img_url = soup.find_all('div',{'class': 'se-component se-image se-l-default'})[-1].find('img')['src']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    korean = re.findall('[ㄱ-ㅣ가-힣]+',img_url)\n",
    "    for i in range(0,len(korean)):\n",
    "        parse.quote_plus(korean[i])\n",
    "        img_url = img_url.replace(korean[i],parse.quote(korean[i]))\n",
    "   \n",
    "    driver.close()\n",
    "    \n",
    "    return title, date, fin, img_url, last_text\n",
    "\n",
    "\n",
    "def make_json(data,filename):\n",
    "    with open(filename+'.json','w',encoding='utf-8') as make_file:\n",
    "        json.dump(data, make_file, ensure_ascii=False, indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_url = get_blog_url('다이슨','20190902','20190908')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<본포스팀은 다이슨으로부터 제품을 재공받아 실재 체험을 통해 작성되었습니다.>\n",
      "제품 소개를 대가로 다이슨으로부터 제품 무상 대여와 원고료를 지원받음\n",
      "0“ | 글과 사진, 이퓨림\n",
      "\n",
      "블로그의 모든 사진과 글은\n",
      "무단도용 / 2차 수정 / 불펌을 금지합니다.          )\n",
      "ㆍ이 포스팅은 다이슨으로부터 제품을 제공받아 실제 체험을 통해 작성되었습니다.      2\n",
      "미 포스팅몬 다이슨으로부터 소정의 고료를 받고\n",
      "직접 체험을 통해 작성된 포스팅입니다.\n",
      "「   9   %\n",
      "\n",
      "~\n",
      "2년 무상 보증      대여 제품 무상 제공     72시간이내 수리       제품 기술 지원\n",
      "{사용자 설명서 참조} 수리기간 동안 불편함을 최소화하기 택배 및 방문 서비스롤 통해제품을 제풍에 대한 문의사항은 평일(월~금)\n",
      "플                   위해 대여 제품을 무상으로 임대해 수거하여 72시간 내 수리를           오전 9시~오후 6시 사이에 전화,\n",
      "보중 기간 이내 수리가 불가능할                 드립니다.                          완료합니다.                  이메일, 채팀을 통해 확인하실 수\n",
      "우 신속하게 교체해 드립니다  ,입반 택비 배송기간 소요,    (제품 배송 및 픽업 시간 제외)         있습니다.\n",
      "\n",
      "(소비자분정해결기준 적용)             여비 45 점수 걷에 한함)\n",
      "* 본 폰스팅은 소정의 원고로를 지급받아 작석되었습닝다.\"\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-81a902bd9292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblog_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_url\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl_to_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mocr_txt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mocr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mblog_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[제,받,고]+[공,아,료]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-150-99538e5c0801>\u001b[0m in \u001b[0;36mocr\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mocr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mimg_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mimg_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptiveThreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mADAPTIVE_THRESH_GAUSSIAN_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"kor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "json_list=[]\n",
    "for i in range(0,30):\n",
    "    title, date, text, img_url, last_text = blog_info(list_url[i])\n",
    "    img = url_to_image(img_url)\n",
    "    ocr_txt = ocr(img)\n",
    "    blog_data = {}\n",
    "    p = re.compile('[제,받,고]+[공,아,료]')\n",
    "    if p.search(ocr_txt):\n",
    "        print(ocr_txt)\n",
    "    elif p.search(last_text):\n",
    "        print(last_text)\n",
    "    else:\n",
    "        blog_data['title'] = title\n",
    "        blog_data['date'] = date\n",
    "        blog_data['text'] = text\n",
    "        json_list.append(blog_data)\n",
    "        \n",
    "make_json(json_list,'광고아닌블로그')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
